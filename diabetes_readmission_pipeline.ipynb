{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Hospital Readmission for Diabetes Patients\n",
    "\n",
    "## Objective\n",
    "Demonstrate an end-to-end machine learning pipeline to predict whether a patient will be readmitted to a hospital after a diabetes diagnosis using data maintained by UCI detailing 10 years of clinical care at U.S. hospitals and integrated delivery networks.\n",
    "\n",
    "## Table of Contents\n",
    "* [Data Loading](#data_loading)\n",
    "* [Data Cleaning & Preprocessing](#data_cleaning)\n",
    "* [Exploratory Data Analysis (EDA)](#eda)\n",
    "    * [Expore numeric data](#eda_numeric)\n",
    "    * [Explore categorical data](#eda_categorical)\n",
    "* [Feature Engineering](#feature_engineering)\n",
    "* [Model Training & Evaluation](#model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import requests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading <a class=\"anchor\" id=\"data_loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Download successful! Extracting files...\n",
      "Files contained in ZIP:\n",
      " diabetic_data.csv, IDS_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# URL of the dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/296/diabetes+130-us+hospitals+for+years+1999-2008.zip\"\n",
    "\n",
    "try:\n",
    "    print(\"Downloading dataset...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status() # raises error for bad HTTP responses\n",
    "\n",
    "    print(\"Download successful! Extracting files...\")\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(response.content)) # open ZIP in memory\n",
    "\n",
    "    # list the files\n",
    "    files_list = zip_file.namelist()\n",
    "    print(\"Files contained in ZIP:\\n\", \", \".join(files_list))\n",
    "\n",
    "    # create a dictionary to store the files\n",
    "    files = {}\n",
    "\n",
    "    for file_name in files_list:\n",
    "        with zip_file.open(file_name) as f:\n",
    "            files[file_name] = pd.read_csv(f)\n",
    "\n",
    "    # assign the DataFrames to variables\n",
    "    df_diabetes = files.get(\"diabetic_data.csv\")\n",
    "    df_ids = files.get(\"IDS_mapping.csv\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading dataset: {e}\")\n",
    "\n",
    "    # TODO: Possibly comment out the next three lines\n",
    "    print(\"Retrieving from local directory...\")\n",
    "    df_diabetes = pd.read_csv(\"~/Downloads/diabetes+130-us+hospitals+for+years+1999-2008/diabetic_data.csv\")\n",
    "    df_ids = pd.read_csv(\"~/Downloads/diabetes+130-us+hospitals+for+years+1999-2008/IDS_mapping.csv\")\n",
    "\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error processing ZIP file\")\n",
    "\n",
    "except OSError as e:\n",
    "    print(f\"Error opening file: {e}\")\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error retrieving file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preprocessing <a class=\"anchor\" id=\"data_cleaning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the IDs DF for merging\n",
    "df_ids.dropna(inplace=True)\n",
    "df_filtered_ids = df_ids[df_ids[\"admission_type_id\"].str.isdigit()].copy()\n",
    "df_grouped_ids = df_filtered_ids.groupby(\"admission_type_id\")[\"description\"].apply(lambda x: \" | \".join(x)).reset_index()\n",
    "\n",
    "# prepare the diabetes DF for merging\n",
    "df_diabetes[\"admission_type_id\"] = df_diabetes[\"admission_type_id\"].astype(str)\n",
    "\n",
    "# merge the DFs\n",
    "df = df_diabetes.merge(df_grouped_ids, how=\"left\", on=\"admission_type_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id                 int64\n",
       "patient_nbr                  int64\n",
       "race                        object\n",
       "gender                      object\n",
       "age                         object\n",
       "weight                      object\n",
       "admission_type_id           object\n",
       "discharge_disposition_id     int64\n",
       "admission_source_id          int64\n",
       "time_in_hospital             int64\n",
       "payer_code                  object\n",
       "medical_specialty           object\n",
       "num_lab_procedures           int64\n",
       "num_procedures               int64\n",
       "num_medications              int64\n",
       "number_outpatient            int64\n",
       "number_emergency             int64\n",
       "number_inpatient             int64\n",
       "diag_1                      object\n",
       "diag_2                      object\n",
       "diag_3                      object\n",
       "number_diagnoses             int64\n",
       "max_glu_serum               object\n",
       "A1Cresult                   object\n",
       "metformin                   object\n",
       "repaglinide                 object\n",
       "nateglinide                 object\n",
       "chlorpropamide              object\n",
       "glimepiride                 object\n",
       "acetohexamide               object\n",
       "glipizide                   object\n",
       "glyburide                   object\n",
       "tolbutamide                 object\n",
       "pioglitazone                object\n",
       "rosiglitazone               object\n",
       "acarbose                    object\n",
       "miglitol                    object\n",
       "troglitazone                object\n",
       "tolazamide                  object\n",
       "examide                     object\n",
       "citoglipton                 object\n",
       "insulin                     object\n",
       "glyburide-metformin         object\n",
       "glipizide-metformin         object\n",
       "glimepiride-pioglitazone    object\n",
       "metformin-rosiglitazone     object\n",
       "metformin-pioglitazone      object\n",
       "change                      object\n",
       "diabetesMed                 object\n",
       "readmitted                  object\n",
       "description                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cast any identifer columns to an object type\n",
    "# cols_to_convert = df.filter(regex=r\"_(?:id|nbr)$\").columns\n",
    "# df[cols_to_convert] = df[cols_to_convert].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns using \"?\" to signify null values:\n",
      " race, weight, payer_code, medical_specialty, diag_1, diag_2, diag_3\n"
     ]
    }
   ],
   "source": [
    "# identify columns using a question mark as a null value\n",
    "question_mark_cols = \", \".join(df.columns[(df == \"?\").any()])\n",
    "print(\"Columns using \\\"?\\\" to signify null values:\\n\", question_mark_cols)\n",
    "\n",
    "# replace \"?\" rows with NaN\n",
    "df.where(df != \"?\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_missing_value_columns(df):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing null statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    # get columns and their missing value counts\n",
    "    missing_values = df.isna().sum()\n",
    "    missing_values = missing_values[missing_values > 0].reset_index()\n",
    "\n",
    "    # rename the columns and calculate the percentage of nulls\n",
    "    missing_values.columns = [\"column_name\", \"null_count\"]\n",
    "    missing_values[\"null_perc\"] = missing_values[\"null_count\"] / df.shape[0]\n",
    "\n",
    "    # sort the values\n",
    "    missing_values.sort_values(by=\"null_perc\", ascending=False, inplace=True)\n",
    "\n",
    "    return missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "      <td>98569</td>\n",
       "      <td>0.968585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max_glu_serum</td>\n",
       "      <td>96420</td>\n",
       "      <td>0.947468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A1Cresult</td>\n",
       "      <td>84748</td>\n",
       "      <td>0.832773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medical_specialty</td>\n",
       "      <td>49949</td>\n",
       "      <td>0.490822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>payer_code</td>\n",
       "      <td>40256</td>\n",
       "      <td>0.395574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>race</td>\n",
       "      <td>2273</td>\n",
       "      <td>0.022336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diag_3</td>\n",
       "      <td>1423</td>\n",
       "      <td>0.013983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diag_2</td>\n",
       "      <td>358</td>\n",
       "      <td>0.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diag_1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column_name  null_count  null_perc\n",
       "1             weight       98569   0.968585\n",
       "7      max_glu_serum       96420   0.947468\n",
       "8          A1Cresult       84748   0.832773\n",
       "3  medical_specialty       49949   0.490822\n",
       "2         payer_code       40256   0.395574\n",
       "0               race        2273   0.022336\n",
       "6             diag_3        1423   0.013983\n",
       "5             diag_2         358   0.003518\n",
       "4             diag_1          21   0.000206"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DF showing missing value statistics\n",
    "display_missing_value_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Rows, cols): (101766, 51)\n",
      "(Rows, cols): (101766, 46)\n",
      "(Rows, cols): (98053, 46)\n"
     ]
    }
   ],
   "source": [
    "# drop columns with 30% or more values missing\n",
    "non_na_vals = df.shape[0] - (0.3 * df.shape[0])\n",
    "df.dropna(thresh=non_na_vals, axis=1, inplace=True)\n",
    "\n",
    "# drop the remaining null rows\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "print(f\"Total duplicate rows: {df.duplicated().sum()}\")\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>encounter_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60765</th>\n",
       "      <td>88785891</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60329</th>\n",
       "      <td>88227540</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17092</th>\n",
       "      <td>23199021</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11723</th>\n",
       "      <td>1660293</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19122</th>\n",
       "      <td>23643405</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>138575831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32757</th>\n",
       "      <td>41013234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>138558794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32759</th>\n",
       "      <td>41014314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34315</th>\n",
       "      <td>4198896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68630 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_nbr  encounter_id\n",
       "60765    88785891            39\n",
       "60329    88227540            23\n",
       "17092    23199021            23\n",
       "11723     1660293            23\n",
       "19122    23643405            22\n",
       "...           ...           ...\n",
       "9499    138575831             1\n",
       "32757    41013234             1\n",
       "9498    138558794             1\n",
       "32759    41014314             1\n",
       "34315     4198896             1\n",
       "\n",
       "[68630 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate patient numbers (i.e., more than one encounter per patient)\n",
    "grouped_patient_nbrs = df.groupby(\"patient_nbr\")[\"encounter_id\"].count().reset_index()\n",
    "grouped_patient_nbrs.sort_values(by=\"encounter_id\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort to keep only the patient number for the most recent encounter\n",
    "df.sort_values(by=[\"patient_nbr\", \"encounter_id\"], ascending=[True, False], inplace=True)\n",
    "df.drop_duplicates(subset=\"patient_nbr\", keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_icd9_to_category(code):\n",
    "    \"\"\"Maps ICD-9 codes to disease categories.\n",
    "\n",
    "    Args:\n",
    "        code: A string value representing an ICD-9 code.\n",
    "    Returns:\n",
    "        category: A string value representing a disease classification.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        code = str(code).strip()\n",
    "        if code.startswith(\"250\"):\n",
    "            category =  \"Diabetes-Related\"\n",
    "        elif code.startswith(\"E\"):\n",
    "            category =  \"Supplementary Classification of External Causes of Injury and Poisoning\"\n",
    "        elif code.startswith(\"V\"):\n",
    "            category =  \"Supplementary Classification of Factors influencing Health Status and Contact with Health Services\"\n",
    "\n",
    "        code = int(float(code))\n",
    "        if 1 <= code <= 139:\n",
    "            category =  \"Infectious and Parasitic Diseases\"\n",
    "        elif 140 <= code <= 239:\n",
    "            category =  \"Neoplasms\"\n",
    "        elif 240 <= code <= 279:\n",
    "            category =  \"Endocrine, Nutritional and Metabolic Diseases, and Immunity Disorders\"\n",
    "        elif 280 <= code <= 289:\n",
    "            category =  \"Diseases of the Blood and Blood-forming Organs\"\n",
    "        elif 290 <= code <= 319:\n",
    "            category =  \"Mental Disorders\"\n",
    "        elif 320 <= code <= 389:\n",
    "            category =  \"Diseases of the Nervous System and Sense Organs\"\n",
    "        elif 390 <= code <= 459:\n",
    "            category =  \"Diseases of the Circulatory System\"\n",
    "        elif 460 <= code <= 519:\n",
    "            category =  \"Diseases of the Respiratory System\"\n",
    "        elif 520 <= code <= 579:\n",
    "            category =  \"Diseases of the Digestive System\"\n",
    "        elif 580 <= code <= 629:\n",
    "            category =  \"Diseases of the Genitourinary System\"\n",
    "        elif 630 <= code <= 679:\n",
    "            category =  \"Complications of Pregnancy, Childbirth, and the Puerperium\"\n",
    "        elif 680 <= code <= 709:\n",
    "            category =  \"Diseases of the Skin and Subcutaneous Tissue\"\n",
    "        elif 710 <= code <= 739:\n",
    "            category =  \"Diseases of the Musculoskeletal System and Connective Tissue\"\n",
    "        elif 740 <= code <= 759:\n",
    "            category =  \"Congenital Anomalies\"\n",
    "        elif 760 <= code <= 779:\n",
    "            category =  \"Certain Conditions originating in the Perinatal Period\"\n",
    "        elif 780 <= code <= 799:\n",
    "            category =  \"Symptoms, Signs and Ill-defined Conditions\"\n",
    "        elif 800 <= code <= 999:\n",
    "            category =  \"Injury and Poisoning\"\n",
    "        else:\n",
    "            category =  \"Other\"\n",
    "\n",
    "    except:\n",
    "        category =  \"Other\"\n",
    "\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ICD-9 codes to disease categories\n",
    "df[[\"disease_class_1\", \"disease_class_2\", \"disease_class_3\"]] = df[[\"diag_1\", \"diag_2\", \"diag_3\"]].apply(lambda col: col.map(map_icd9_to_category, na_action=\"ignore\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>\n",
    "\n",
    "### Explore numeric data <a class=\"anchor\" id=\"eda_numeric\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at descriptive statistics for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_distributions(df):\n",
    "    \"\"\"Generates a grid of boxplots and histograms for numeric columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset with numeric data.\n",
    "    \"\"\"\n",
    "\n",
    "    # identify numeric columns\n",
    "    numeric_cols = sorted(df.select_dtypes(include=\"number\").columns)\n",
    "\n",
    "    # get the number of numeric columns\n",
    "    num_cols = len(numeric_cols)\n",
    "\n",
    "    # create a figure and set of subplots\n",
    "    fig, axes = plt.subplots(num_cols, 2, figsize=(10, 5 * num_cols))\n",
    "\n",
    "    # create a side-by-side boxplot and histogram for each row\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        sns.boxplot(data=df, x=col, color=\"mediumvioletred\", ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"Boxplot of {col}\")\n",
    "\n",
    "        sns.histplot(data=df, x=col, color=\"lightcoral\", ax=axes[i, 1])\n",
    "        axes[i, 1].set_title(f\"Histogram of {col}\")\n",
    "\n",
    "    # prevent overlap and display figure\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the distributions in the numeric data\n",
    "plot_numeric_distributions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_skewness_columns(df):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' skewness.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset containing numeric data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing skewness values.\n",
    "    \"\"\"\n",
    "\n",
    "    # check for skewness and rename columns\n",
    "    skewness = df.select_dtypes(include=\"number\").skew().reset_index()\n",
    "    skewness.columns = [\"column_name\", \"value\"]\n",
    "\n",
    "    # categorize the skewness\n",
    "    conditions = [skewness[\"value\"].abs().between(0.5, 1), skewness[\"value\"].abs() > 1]\n",
    "    choices = [\"Moderate\", \"High\"]\n",
    "    skewness[\"skew_category\"] = np.select(conditions, choices, default=\"Symmetric\")\n",
    "\n",
    "    # sort the values\n",
    "    skewness.sort_values(by=\"value\", ascending=False, inplace=True)\n",
    "\n",
    "    return skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DF showing skewness\n",
    "display_skewness_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the strength of relationships among numeric columns\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_df = df.filter(regex=r\"^(?!.*_(?:id|nbr)$)\").corr(numeric_only=True)\n",
    "sns.heatmap(corr_df, cmap=\"PuRd\", annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore categorical data <a class=\"anchor\" id=\"eda_categorical\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at descriptive statistics for categorical columns\n",
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cardinality_columns(df):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' cardinality.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing cardinality statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    # get columns and their number of unique values\n",
    "    cardinal_values = df.select_dtypes(include=[\"category\", \"object\"]).nunique().reset_index()\n",
    "\n",
    "    # rename the columns and categorize the skewness\n",
    "    cardinal_values.columns = [\"column_name\", \"num_unique\"]\n",
    "    cardinal_values[\"cardinality\"] = cardinal_values[\"num_unique\"].apply(lambda x: \"Low\" if x < 15 else \"Moderate\" if 15 <= x < 50 else \"High\")\n",
    "\n",
    "    # sort the values\n",
    "    cardinal_values.sort_values(by=\"num_unique\", ascending=False, inplace=True)\n",
    "\n",
    "    return cardinal_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DF showing cardinality\n",
    "display_cardinality_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_distributions(df, threshold=5):\n",
    "    \"\"\"Generates a grid of violin and count plots for categorical columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset with categorical data.\n",
    "        threshold (int): The max number of unique values a column should have.\n",
    "    \"\"\"\n",
    "\n",
    "    # identify categorical columns and remove ID columns\n",
    "    unique_values = df.select_dtypes(include=[\"category\", \"object\"]).nunique()\n",
    "    categorical_cols = sorted(unique_values[unique_values.values <= threshold].index)\n",
    "\n",
    "    # get the number of categorical columns\n",
    "    num_cols = len(categorical_cols)\n",
    "\n",
    "    # create a figure and set of subplots\n",
    "    fig, axes = plt.subplots(num_cols, 2, figsize=(10, 5 * num_cols))\n",
    "\n",
    "    # create a side-by-side violin plot and count plot for each row\n",
    "    for i, col in enumerate(categorical_cols):\n",
    "\n",
    "        sns.violinplot(data=df, x=col, color=\"mediumvioletred\", ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"Boxplot of {col}\")\n",
    "        axes[i, 0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        sns.countplot(data=df, x=col, color=\"lightcoral\", ax=axes[i, 1])\n",
    "        axes[i, 1].set_title(f\"Histogram of {col}\")\n",
    "        axes[i, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # prevent overlap and display figure\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the distributions in the categorical data\n",
    "plot_categorical_distributions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_chi_square_columns(df, target_col):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset containing categorical columns.\n",
    "        target_col (str): A variable that is being predicted on.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing chi-square and p-value statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    # get categorical columns, except for identifier columns and the target\n",
    "    categorical_cols = df.select_dtypes(include=[\"category\", \"object\"]).columns\n",
    "    categorical_df = df[categorical_cols].copy()\n",
    "    categorical_df.drop(columns=[\"encounter_id\", \"patient_nbr\", target_col])\n",
    "\n",
    "    # initialize a dictionary to hold the chi-square test results\n",
    "    result_dict = {\"column_name\": [], \"chi_sq\": [], \"p_val\": []}\n",
    "\n",
    "    for col in categorical_df:\n",
    "\n",
    "        # compute the contingency table\n",
    "        contingency_table = pd.crosstab(df[col], df[target_col])\n",
    "\n",
    "        # computes the chi-square statistic and p-value\n",
    "        chi_sq, p_val, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "        # append the results\n",
    "        result_dict[\"column_name\"].append(col)\n",
    "        result_dict[\"chi_sq\"].append(round(chi_sq, 2))\n",
    "        result_dict[\"p_val\"].append(round(p_val, 2))\n",
    "\n",
    "    # create a DataFrame from the results\n",
    "    result_df = pd.DataFrame(result_dict).sort_values(by=\"p_val\")\n",
    "    result_df[\"is_significant\"] = result_df[\"p_val\"] < 0.05\n",
    "\n",
    "    print(f\"Columns with/without a significant association to the column, {target_col}:\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_chi_square_columns(df, \"readmitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a class=\"anchor\" id=\"feature_engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
